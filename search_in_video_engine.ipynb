{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SEARCH IN VIDEO ENGINE"
      ],
      "metadata": {
        "id": "7Nod0LshiUIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R3hzEJehDfz"
      },
      "outputs": [],
      "source": [
        "# Install Required Libraries\n",
        "\n",
        "!pip install moviepy pydub SpeechRecognition indic-transliteration yt-dlp\n",
        "!pip install deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "from moviepy.editor import VideoFileClip\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "from difflib import get_close_matches\n",
        "import yt_dlp\n",
        "import os\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "from deep_translator import GoogleTranslator"
      ],
      "metadata": {
        "id": "fYDGS082hlhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YouTube Video Download Functions\n",
        "\n",
        "def _get_video_id_from_url(url: str):\n",
        "    parsed = urlparse(url)\n",
        "    qs = parse_qs(parsed.query)\n",
        "    if 'v' in qs and qs['v']:\n",
        "        return qs['v'][0]\n",
        "    host = parsed.netloc.lower().replace('www.', '')\n",
        "    if host == 'youtu.be':\n",
        "        return parsed.path.lstrip('/').split('/')[0]\n",
        "    if parsed.path and '/shorts/' in parsed.path:\n",
        "        try:\n",
        "            return parsed.path.split('/shorts/')[1].split('/')[0]\n",
        "        except IndexError:\n",
        "            return None\n",
        "    frag_qs = parse_qs(parsed.fragment)\n",
        "    if 'v' in frag_qs and frag_qs['v']:\n",
        "        return frag_qs['v'][0]\n",
        "    return None\n",
        "\n",
        "def _normalize_to_watch_url(url: str):\n",
        "    vid = _get_video_id_from_url(url)\n",
        "    if vid:\n",
        "        return f\"https://www.youtube.com/watch?v={vid}\", vid\n",
        "    return url, None\n",
        "\n",
        "def download_youtube_video(url, workdir=\"downloads\"):\n",
        "    print(\"Start downloading Youtube video...\")\n",
        "    os.makedirs(workdir, exist_ok=True)\n",
        "    clean_url, requested_vid = _normalize_to_watch_url(url)\n",
        "    print(f\"Normalized URL: {clean_url}  (requested id: {requested_vid})\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
        "        'outtmpl': os.path.join(workdir, '%(id)s.%(ext)s'),\n",
        "        'merge_output_format': 'mp4',\n",
        "        'noplaylist': True,\n",
        "        'quiet': True,\n",
        "        'no_warnings': True,\n",
        "    }\n",
        "\n",
        "    chosen_info = None\n",
        "    downloaded_path = None\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(clean_url, download=True)\n",
        "\n",
        "        if isinstance(info, dict) and 'entries' in info and info['entries']:\n",
        "            entries = [e for e in info['entries'] if e]\n",
        "            if requested_vid:\n",
        "                for e in entries:\n",
        "                    if e.get('id') == requested_vid:\n",
        "                        chosen_info = e\n",
        "                        break\n",
        "            if chosen_info is None:\n",
        "                chosen_info = entries[0]\n",
        "        else:\n",
        "            chosen_info = info\n",
        "\n",
        "        prepared = ydl.prepare_filename(chosen_info)\n",
        "        expected_mp4 = os.path.splitext(prepared)[0] + '.mp4'\n",
        "\n",
        "        if os.path.exists(expected_mp4):\n",
        "            downloaded_path = expected_mp4\n",
        "        else:\n",
        "            files = [os.path.join(workdir, f) for f in os.listdir(workdir) if os.path.isfile(os.path.join(workdir, f))]\n",
        "            if not files:\n",
        "                raise FileNotFoundError(\"Downloaded file not found in working directory.\")\n",
        "            downloaded_path = max(files, key=os.path.getsize)\n",
        "\n",
        "    print(f\"Downloaded file: {downloaded_path}\")\n",
        "    return downloaded_path, chosen_info or info\n"
      ],
      "metadata": {
        "id": "JsXJBux4hlfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio Extraction & Splitting\n",
        "\n",
        "def extract_audio_from_video(video_file, audio_file):\n",
        "    video = VideoFileClip(video_file)\n",
        "    video.audio.write_audiofile(audio_file)\n",
        "\n",
        "def get_chunk_length(video_duration):\n",
        "    return 15000  # 15 seconds\n",
        "\n",
        "def split_audio(audio_file, chunk_length_ms):\n",
        "    audio = AudioSegment.from_wav(audio_file)\n",
        "    chunks = []\n",
        "    overlap = 3000\n",
        "    start = 0\n",
        "    while start < len(audio):\n",
        "        end = start + chunk_length_ms\n",
        "        chunks.append(audio[start:end])\n",
        "        start += chunk_length_ms - overlap\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "ox1GplhEhldB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Speech Recognition Functions\n",
        "\n",
        "def transcribe_audio_chunk(chunk, recognizer, language='en-US'):\n",
        "    with chunk.export(format=\"wav\") as source:\n",
        "        audio = sr.AudioFile(source)\n",
        "        with audio as audio_source:\n",
        "            audio_data = recognizer.record(audio_source)\n",
        "            try:\n",
        "                return recognizer.recognize_google(audio_data, language=language)\n",
        "            except sr.UnknownValueError:\n",
        "                return \"\"\n",
        "            except sr.RequestError as e:\n",
        "                print(f\"Request Error: {e}\")\n",
        "                return \"\"\n",
        "\n",
        "def milliseconds_to_hms(milliseconds):\n",
        "    seconds = milliseconds // 1000\n",
        "    minutes = seconds // 60\n",
        "    hours = minutes // 60\n",
        "    minutes = minutes % 60\n",
        "    seconds = seconds % 60\n",
        "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n"
      ],
      "metadata": {
        "id": "9kVDZTLnhla4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search and Transliteration Functions\n",
        "\n",
        "def search_word_in_transcript(transcript, search_words, chunk_start_time, chunk_length_ms, fuzzy_match, cutoff):\n",
        "    timestamps = {}\n",
        "    word_times = {}\n",
        "    words = transcript.lower().split()\n",
        "    search_words = [word.lower() for word in search_words]\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word in search_words:\n",
        "            word_time = chunk_start_time + (i / len(words)) * chunk_length_ms\n",
        "            word_time_hms = milliseconds_to_hms(word_time)\n",
        "            timestamps.setdefault(word, []).append(word_time_hms)\n",
        "            word_times.setdefault(word, []).append(word_time)\n",
        "        elif fuzzy_match:\n",
        "            similar_words = get_close_matches(word, search_words, n=1, cutoff=cutoff)\n",
        "            if similar_words:\n",
        "                closest_word = similar_words[0]\n",
        "                word_time = chunk_start_time + (i / len(words)) * chunk_length_ms\n",
        "                word_time_hms = milliseconds_to_hms(word_time)\n",
        "                timestamps.setdefault(closest_word, []).append(word_time_hms)\n",
        "                word_times.setdefault(closest_word, []).append(word_time)\n",
        "\n",
        "    concatenated_words = []\n",
        "    concatenated_times = []\n",
        "    sorted_words = sorted(word_times.keys(), key=lambda w: min(word_times[w]) if word_times[w] else float('inf'))\n",
        "\n",
        "    i = 0\n",
        "    while i < len(sorted_words) - 1:\n",
        "        current_word = sorted_words[i]\n",
        "        current_times = word_times[current_word]\n",
        "        j = i + 1\n",
        "        concatenated = current_word\n",
        "        min_time = min(current_times)\n",
        "\n",
        "        while j < len(sorted_words):\n",
        "            next_word = sorted_words[j]\n",
        "            next_times = word_times[next_word]\n",
        "\n",
        "            if abs(min(next_times) - min(current_times)) <= 1000:\n",
        "                concatenated += \" \" + next_word\n",
        "                j += 1\n",
        "                current_times = next_times\n",
        "                min_time = min(min_time, min(current_times))\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        if concatenated != current_word:\n",
        "            concatenated_words.append(concatenated)\n",
        "            concatenated_times.append(milliseconds_to_hms(min_time))\n",
        "\n",
        "        i = j\n",
        "\n",
        "    return timestamps, concatenated_words, concatenated_times\n",
        "\n",
        "def transliterate_search_words(words):\n",
        "    translated_words = []\n",
        "    for word in words:\n",
        "        try:\n",
        "            hindi_script = GoogleTranslator(source='en', target='hi').translate(word)\n",
        "            translated_words.append(hindi_script)\n",
        "        except Exception as e:\n",
        "            print(f\"Translation error: {e}\")\n",
        "            translated_words.append(word)\n",
        "    return translated_words\n"
      ],
      "metadata": {
        "id": "N5MkFHXxhlYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "\n",
        "def main(video_file_or_url, search_string, language='en'):\n",
        "    audio_file = \"audio.wav\"\n",
        "\n",
        "    if video_file_or_url.startswith(\"http://\") or video_file_or_url.startswith(\"https://\"):\n",
        "        video_file, info = download_youtube_video(video_file_or_url)\n",
        "    else:\n",
        "        video_file = video_file_or_url\n",
        "\n",
        "    extract_audio_from_video(video_file, audio_file)\n",
        "    video = VideoFileClip(video_file)\n",
        "    video_duration = video.duration\n",
        "    chunk_length_ms = get_chunk_length(video_duration)\n",
        "\n",
        "    search_words = search_string.split()\n",
        "    if language == 'hi':\n",
        "        search_words = transliterate_search_words(search_words)\n",
        "\n",
        "    print(f\"Searching for the following words: {search_words}\")\n",
        "\n",
        "    fuzzy_match_input = input(\"Do you want to enable fuzzy matching for similar words? (yes/no): \").strip().lower()\n",
        "    fuzzy_match = fuzzy_match_input == 'yes'\n",
        "\n",
        "    cutoff = 0.8\n",
        "    if fuzzy_match:\n",
        "        cutoff_input = cutoff_input = input(\"Enter the cutoff value for fuzzy matching between 0 and 1 [1 = exact match only, 0 = very loose match (almost any similar word will match]: \")\n",
        "\n",
        "        try:\n",
        "            cutoff = float(cutoff_input)\n",
        "            if not (0 <= cutoff <= 1):\n",
        "                print(\"Invalid cutoff value. Using default cutoff of 0.8.\")\n",
        "                cutoff = 0.8\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Using default cutoff of 0.8.\")\n",
        "\n",
        "    print(f\"The search word(s) to be used: {', '.join(search_words)}\")\n",
        "\n",
        "    chunks = split_audio(audio_file, chunk_length_ms)\n",
        "    recognizer = sr.Recognizer()\n",
        "    all_timestamps = {}\n",
        "    all_concatenated_words = []\n",
        "    all_concatenated_times = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_start_time = i * (chunk_length_ms - 3000)\n",
        "        print(f\"Processing chunk {i + 1}/{len(chunks)}...\")\n",
        "        text = transcribe_audio_chunk(chunk, recognizer, language='hi-IN' if language == 'hi' else 'en-US')\n",
        "        print(f\"Transcription of chunk {i + 1}: {text}\")\n",
        "\n",
        "        timestamps, concatenated_words, concatenated_times = search_word_in_transcript(\n",
        "            text, search_words, chunk_start_time, chunk_length_ms, fuzzy_match, cutoff\n",
        "        )\n",
        "\n",
        "        for word, times in timestamps.items():\n",
        "            all_timestamps.setdefault(word, []).extend(times)\n",
        "\n",
        "        all_concatenated_words.extend(concatenated_words)\n",
        "        all_concatenated_times.extend(concatenated_times)\n",
        "\n",
        "    if all_timestamps:\n",
        "        print(\"Unique timestamps for searched words:\")\n",
        "        for word, times in all_timestamps.items():\n",
        "            print(f\"{word}: {', '.join(set(times))}\")\n",
        "\n",
        "    if all_concatenated_words:\n",
        "        print(\"Concatenated words with unique timestamps:\")\n",
        "        unique_concatenated = {}\n",
        "        for word, time in zip(all_concatenated_words, all_concatenated_times):\n",
        "            unique_concatenated.setdefault(word, set()).add(time)\n",
        "\n",
        "        for word, times in unique_concatenated.items():\n",
        "            print(f\"{word}: {', '.join(times)}\")\n",
        "\n",
        "    if not all_timestamps:\n",
        "        print(\"No word(s) found.\")\n",
        "    if not all_concatenated_words and len(search_string.split()) > 1:\n",
        "        print(\"No concatenated word(s) found.\")\n"
      ],
      "metadata": {
        "id": "fVnqM8nrhlVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Program\n",
        "\n",
        "video_file_or_url = input(\"Enter the path of the video OR YouTube URL: \")\n",
        "search_string = input(\"Enter sentence/words to search for in the video: \")\n",
        "language = input(\"Enter the language of the video (en/hi): \").strip().lower()\n",
        "\n",
        "main(video_file_or_url, search_string, language)"
      ],
      "metadata": {
        "id": "__JVShaNhlNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}